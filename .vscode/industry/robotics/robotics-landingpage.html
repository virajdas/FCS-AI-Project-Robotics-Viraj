<!DOCTYPE html>
<html lang="en">
<head>
    <title>Robotics - Landing</title>
    <link rel="icon" type="image/x-icon" href="../../images/Innovation Academy Phoenix.svg">
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="robotics.css" />
    <noscript><link rel="stylesheet" href="../../assets/css/noscript.css" /></noscript>
</head>
<body class="body">
    <header class="header">
        <nav class="navigation">
            <a href="../../index.html">Home</a>
            <a href="robotics-landingpage.html" class="active">Landing</a>
            <a href="robotics-information.html">Information</a>
            <a href="robotics-aboutme.html">About Us</a>
        </nav>
    </header>
    <section class="parallax">
        <img src="../../images/robotics/landing/Background.png" id="parallax-1">
        <h2 id="text">ROBOTICS</h2>
        <p id="subtext">AI-driven robotics transforms<br>industries through smart automation.</p>
        <img src="../../images/robotics/landing/Earth.png" id="parallax-2">
        <img src="../../images/robotics/landing/Robot.png" id="parallax-3">
    </section>
    <section class="sec ai-section">
        <div class="ai-block fade-in" style="animation-delay:0.1s;">
            <h2 class="ai-title">Current Level of AI Usage</h2>
            <div class="ai-desc">
                <p>
                    <strong>AI in robotics is <span class="ai-highlight">high and still rising</span>.</strong>
                    Robotics is one of the most AI-intensive industries, with intelligent systems powering everything from industrial arms to autonomous vehicles. AI enables robots to sense their environment, interpret complex data, and make decisions in real time. 
                </p>
                <p>
                    <b>Key AI technologies:</b> <br>
                    <ul>
                        <li>Computer vision for object detection, tracking, and scene understanding</li>
                        <li>SLAM (Simultaneous Localization and Mapping) for navigation in unknown environments</li>
                        <li>Path planning algorithms (A*, D*, RRT) for efficient movement</li>
                        <li>Machine learning for adaptive control, anomaly detection, and predictive maintenance</li>
                        <li>Natural language processing for human-robot interaction</li>
                    </ul>
                </p>
                <p>
                    <b>Industry impact:</b> <br>
                    AI-driven robots are deployed in hospitals for delivery and disinfection, in factories for precision assembly and inspection, in agriculture for crop monitoring and harvesting, and in logistics for warehouse automation. The use of AI is expanding rapidly as robots become more autonomous and capable.
                </p>
            </div>
        </div>
        <div class="ai-block fade-in" style="animation-delay:0.2s;">
            <h2 class="ai-title">Historical Growth of AI in Robotics</h2>
            <div class="ai-timeline">
                <div class="ai-timeline-event">
                    <div class="ai-timeline-year-box">
                        <span class="ai-timeline-year">1960s–1970s</span>
                    </div>
                    <span class="ai-timeline-dot"></span>
                    <span class="ai-timeline-desc">
                        <strong>First AI Robot Era:</strong> Shakey the Robot (SRI) was the first robot to combine vision, planning, and action. The development of A* search (1968) provided a foundation for robotic navigation and manipulation.
                    </span>
                </div>
                <div class="ai-timeline-event">
                    <div class="ai-timeline-year-box">
                        <span class="ai-timeline-year">1980s</span>
                    </div>
                    <span class="ai-timeline-dot"></span>
                    <span class="ai-timeline-desc">
                        <strong>Behavior-Based Control:</strong> Rodney Brooks' subsumption architecture enabled robots to react to their environment in real time, laying the groundwork for modern autonomous systems.
                    </span>
                </div>
                <div class="ai-timeline-event">
                    <div class="ai-timeline-year-box">
                        <span class="ai-timeline-year">1990s–2000s</span>
                    </div>
                    <span class="ai-timeline-dot"></span>
                    <span class="ai-timeline-desc">
                        <strong>Probabilistic Robotics & SLAM:</strong> Advances in probabilistic methods and SLAM allowed robots to build maps and localize themselves in unknown environments, a breakthrough for mobile robotics.
                    </span>
                </div>
                <div class="ai-timeline-event">
                    <div class="ai-timeline-year-box">
                        <span class="ai-timeline-year">2010s</span>
                    </div>
                    <span class="ai-timeline-dot"></span>
                    <span class="ai-timeline-desc">
                        <strong>Deep Perception & Resilient Autonomy:</strong> The rise of deep learning improved robot perception and decision-making, enabling robust deployment in logistics, healthcare, and exploration.
                    </span>
                </div>
                <div class="ai-timeline-event">
                    <div class="ai-timeline-year-box">
                        <span class="ai-timeline-year">2020s</span>
                    </div>
                    <span class="ai-timeline-dot"></span>
                    <span class="ai-timeline-desc">
                        <strong>Learning-Based Control & Domain Rollouts:</strong> Robots now use reinforcement learning and large datasets to adapt to new tasks and environments, with mission-critical deployments in hospitals, space, and industry.
                    </span>
                </div>
            </div>
        </div>
        <div class="ai-block fade-in" style="animation-delay:0.3s;">
            <h2 class="ai-title center">First Known AI Application</h2>
            <div class="shakey-highlight-container">
                <div class="shakey-robot-logo">
                    <img src="https://media.wired.com/photos/59331ef426780e6c04d2e6ee/master/pass/500004692-03-01.jpeg" alt="Shakey the Robot">
                </div>
                <div class="shakey-robot-title">
                    <span class="shakey-robot-glow">SHAKEY THE ROBOT</span>
                    <span class="shakey-robot-years">1966–1972</span>
                </div>
                <ul class="ai-list shakey-robot-list">
                    <li><strong>First mobile system to <span class="shakey-robot-keyword">perceive</span>, <span class="shakey-robot-keyword">plan</span>, and <span class="shakey-robot-keyword">act</span> using integrated AI.</strong></li>
                    <li>Used computer vision to interpret its environment and symbolic planning (STRIPS) to decide actions.</li>
                    <li>Demonstrated autonomous navigation, obstacle avoidance, and task completion in a structured environment.</li>
                    <li>Influenced generations of robots and AI research, setting the standard for integrated robotic intelligence.</li>
                    <li>Shakey’s architecture is echoed in today’s autonomous vehicles, drones, and service robots.</li>
                </ul>
            </div>
        </div>
        <div class="ai-block fade-in" style="animation-delay:0.4s;">
            <h2 class="ai-title">Notable Applications</h2>
            <div class="ai-app-grid">
                <div class="ai-app-card">
                    <strong>Industrial & Human-Robot Collaboration (HRC)</strong>
                    <p>Robots work alongside humans in factories, using AI for safety, adaptability, and efficient task sharing. Examples include collaborative arms, automated inspection, and predictive maintenance.</p>
                </div>
                <div class="ai-app-card">
                    <strong>Intralogistics / Warehouses (AMRs)</strong>
                    <p>Autonomous mobile robots optimize warehouse operations, handling goods, inventory, and deliveries. AI enables dynamic path planning, fleet coordination, and real-time obstacle avoidance.</p>
                </div>
                <div class="ai-app-card">
                    <strong>Healthcare & Surgery</strong>
                    <p>Robots assist in surgery, patient transport, and hospital logistics. AI powers autonomous surgical systems (e.g., STAR), navigation in clinical environments, and regulatory compliance.</p>
                </div>
                <div class="ai-app-card">
                    <strong>Space Robotics</strong>
                    <p>Mars rovers and space probes use AI for autonomous navigation, scientific data collection, and system health monitoring. Perseverance’s AutoNav system is a prime example.</p>
                </div>
                <div class="ai-app-card">
                    <strong>Underwater / Marine</strong>
                    <p>Autonomous underwater vehicles (AUVs) use AI for mapping, tracking ocean phenomena, and adaptive mission planning, expanding the reach of marine research.</p>
                </div>
                <div class="ai-app-card">
                    <strong>Aerial Drones</strong>
                    <p>Drones perform autonomous flight in GPS-denied environments, using onboard sensors and AI for collision avoidance, mapping, and delivery.</p>
                </div>
                <div class="ai-app-card">
                    <strong>Agriculture</strong>
                    <p>Robots monitor crops, automate harvesting, spraying, and weeding, and use AI for yield prediction and disease detection, improving efficiency and sustainability.</p>
                </div>
                <div class="ai-app-card">
                    <strong>Construction & Mining</strong>
                    <p>AI-driven excavators and mining robots automate material handling, site mapping, and equipment operation, increasing safety and productivity.</p>
                </div>
                <div class="ai-app-card">
                    <strong>Service & Domestic Robots</strong>
                    <p>Robots assist with cleaning, delivery, and personal care in homes and businesses. AI enables natural interaction, trust, and adaptability to user needs.</p>
                </div>
            </div>
        </div>
        <div class="ai-block fade-in" style="animation-delay:0.5s;">
            <h2 class="ai-title">Foundational Methods</h2>
            <ul class="ai-list">
                <li>
                    <strong>A* Search:</strong>
                    <br>
                    Developed in 1968, A* is a heuristic pathfinding algorithm that finds the shortest path between two points. It is foundational for robot navigation, manipulation, and task planning. A* is used in mobile robots, autonomous vehicles, and drones to efficiently traverse complex environments, avoid obstacles, and optimize routes. Its flexibility allows integration with real-time sensor data and dynamic replanning, making it a core tool for both industrial and service robotics. <br>
                    <em>(Hart, P. E., Nilsson, N. J., & Raphael, B., 1968)</em>
                </li>
                <li>
                    <strong>Subsumption Architecture:</strong>
                    <br>
                    Introduced by Rodney Brooks in the 1980s, subsumption architecture is a layered control system where simple behaviors are combined to produce complex, adaptive actions. Each layer operates independently, allowing robots to react quickly to changes in their environment. This method is crucial for real-time autonomy, enabling robots to handle unexpected events, recover from errors, and operate safely alongside humans. It remains influential in modern collaborative robots and autonomous agents. <br>
                    <em>(Villani, V., Pini, F., Leali, F., & Secchi, C., 2018)</em>
                </li>
                <li>
                    <strong>SLAM (Simultaneous Localization and Mapping):</strong>
                    <br>
                    SLAM algorithms allow robots to build a map of an unknown environment while simultaneously tracking their own location within it. Probabilistic approaches (EKF, particle filters, graph-based SLAM) provide robust solutions for navigation in GPS-denied or dynamic settings. SLAM is essential for autonomous vehicles, drones, underwater robots, and planetary rovers, enabling long-term autonomy and exploration in complex, unstructured environments. <br>
                    <em>(Bailey, T., & Durrant-Whyte, H., 2006; Cadena, C., Carlone, L., Carrillo, H., Latif, Y., Scaramuzza, D., Neira, J., Reid, I., & Leonard, J. J., 2016)</em>
                </li>
                <li>
                    <strong>Probabilistic Reasoning & Bayesian Estimation:</strong>
                    <br>
                    Modern robotics relies on probabilistic models to handle uncertainty in perception, localization, and decision-making. Bayesian estimation techniques allow robots to fuse noisy sensor data, predict future states, and make reliable decisions under uncertainty. These methods underpin SLAM, sensor fusion, and adaptive control, and are critical for safe operation in unpredictable real-world scenarios. <br>
                    <em>(Dissanayake, M., Newman, P., Clark, S., Durrant-Whyte, H., & Csorba, M., 2001)</em>
                </li>
                <li>
                    <strong>Deep Learning:</strong>
                    <br>
                    Deep neural networks have revolutionized robot perception, enabling robust object recognition, semantic segmentation, and scene understanding. Deep learning is also used for end-to-end control, grasping, and manipulation, allowing robots to learn complex tasks from large datasets. Advances in transfer learning and reinforcement learning further enable robots to adapt to new environments and tasks with minimal human intervention. <br>
                    <em>(Cadena, C., Carlone, L., Carrillo, H., Latif, Y., Scaramuzza, D., Neira, J., Reid, I., & Leonard, J. J., 2016)</em>
                </li>
                <li>
                    <strong>Reinforcement Learning:</strong>
                    <br>
                    RL allows robots to learn optimal behaviors through trial and error, guided by reward signals. It is used for motion planning, manipulation, and autonomous decision-making in dynamic environments. RL is increasingly applied in industrial automation, healthcare robotics, and autonomous vehicles to improve adaptability and performance. <br>
                    <em>(Mohta, K., Mulgaonkar, Y., Watterson, M., Liu, S., Qu, C., Makineni, A., … Kumar, V., 2018)</em>
                </li>
                <li>
                    <strong>Sensor Fusion:</strong>
                    <br>
                    Combining data from multiple sensors (lidar, cameras, IMUs, GPS) improves robustness and accuracy in perception and localization. Sensor fusion techniques are vital for safe navigation, obstacle avoidance, and environment mapping, especially in challenging or cluttered settings. <br>
                    <em>(Gao, F., Lin, Y., Shen, S., & Liu, S., 2019)</em>
                </li>
                <li>
                    <strong>Human-Robot Interaction (HRI):</strong>
                    <br>
                    AI-driven HRI methods enable natural communication, intent recognition, and safe collaboration between humans and robots. Techniques include speech recognition, gesture interpretation, and adaptive interfaces, which are essential for service robots, collaborative manufacturing, and healthcare applications. <br>
                    <em>(Villani, V., Pini, F., Leali, F., & Secchi, C., 2018)</em>
                </li>
            </ul>
        </div>
        <div class="ai-block fade-in" style="animation-delay:0.6s;">
            <h2 class="ai-title">AI Usage Over Time</h2>
            <ul class="ai-list">
                <li>
                    <strong>Symbolic Era (1960s–1970s):</strong>
                    <br>
                    Early robots relied on symbolic reasoning and rule-based planning (STRIPS, A*). These systems could solve structured problems and execute predefined tasks, but struggled with uncertainty and dynamic environments. Shakey the Robot exemplified this era, integrating vision, planning, and action in a controlled setting. <br>
                    <em>(Nilsson, N. J., 1984; Hart, P. E., Nilsson, N. J., & Raphael, B., 1968)</em>
                </li>
                <li>
                    <strong>Reactive Era (1980s):</strong>
                    <br>
                    The introduction of subsumption architecture enabled robots to respond in real time to environmental changes. Reactive control allowed for robust behavior in open worlds, with robots able to avoid obstacles, recover from errors, and operate safely in unpredictable conditions. This era saw the rise of autonomous mobile robots and early collaborative systems. <br>
                    <em>(Villani, V., Pini, F., Leali, F., & Secchi, C., 2018)</em>
                </li>
                <li>
                    <strong>Probabilistic Era (1990s–2000s):</strong>
                    <br>
                    Probabilistic robotics brought Bayesian estimation and SLAM to the forefront, allowing robots to localize and map unknown environments with high reliability. This enabled deployment in warehouses, hospitals, and outdoor settings, and laid the groundwork for long-term autonomy and exploration. <br>
                    <em>(Bailey, T., & Durrant-Whyte, H., 2006; Dissanayake, M., Newman, P., Clark, S., Durrant-Whyte, H., & Csorba, M., 2001)</em>
                </li>
                <li>
                    <strong>Learning-Driven Era (2010s–2020s):</strong>
                    <br>
                    Advances in deep learning, reinforcement learning, and big data have transformed robotics. Robots now learn from experience, adapt to new tasks, and operate in highly dynamic environments. Applications include autonomous vehicles, surgical robots, agricultural platforms, and drones. AI-driven robots are increasingly capable of complex perception, manipulation, and decision-making, with mission-critical deployments in healthcare, logistics, and exploration. <br>
                    <em>(Cadena, C., Carlone, L., Carrillo, H., Latif, Y., Scaramuzza, D., Neira, J., Reid, I., & Leonard, J. J., 2016; Saeidi, H., Opfermann, J. D., Liu, Y., Orosco, R. K., Krieger, A., & Kim, P. C. W., 2022)</em>
                </li>
                <li>
                    <strong>Current Trends:</strong>
                    <br>
                    Today, AI is used for predictive maintenance, anomaly detection, multi-agent coordination, and ethical decision-making. Robots collaborate with humans, learn from demonstration, and operate in mixed reality environments. The integration of cloud robotics and edge AI enables scalable, distributed intelligence across fleets of robots. <br>
                    <em>(Lackner, T., & Gronalt, M., 2024; Fragapane, G., de Koster, R., Sgarbossa, F., & Strandhagen, J. O., 2021)</em>
                </li>
                <li>
                    <strong>Future Directions:</strong>
                    <br>
                    Ongoing research focuses on explainable AI, trustworthy autonomy, and lifelong learning. The goal is to create robots that can safely and transparently interact with humans, adapt to evolving tasks, and contribute to society in meaningful ways. <br>
                    <em>(Cadena, C., Carlone, L., Carrillo, H., Latif, Y., Scaramuzza, D., Neira, J., Reid, I., & Leonard, J. J., 2016)</em>
                </li>
            </ul>
        </div>
        <div class="ai-block fade-in" style="animation-delay:0.7s;">
            <h2 class="ai-title">Conclusion</h2>
            <div class="ai-desc">
                <strong>AI usage in robotics is <span class="ai-highlight">high</span> and foundational.</strong>
                <br>
                Robotics has progressed from simple, rule-based machines to sophisticated, learning-driven systems capable of autonomous operation in complex, dynamic environments. Foundational methods such as A*, subsumption architecture, SLAM, and deep learning have enabled robots to perceive, plan, and act with increasing intelligence and reliability.
                <br><br>
                Today, AI-powered robots are deployed in mission-critical roles across healthcare, logistics, manufacturing, agriculture, mining, space, and domestic settings. They collaborate with humans, adapt to new challenges, and operate safely in unpredictable conditions. Peer-reviewed research confirms that AI is central to robotics, driving innovation and expanding the boundaries of what robots can achieve.
                <br><br>
                The future of robotics will be shaped by advances in explainable AI, ethical autonomy, and lifelong learning. As robots become more capable and integrated into society, they will play a vital role in addressing global challenges, improving quality of life, and enabling new forms of exploration and productivity. The synergy between AI and robotics promises a future where intelligent machines enhance human capabilities and transform industries worldwide.
                <br><br>
                <em>For further reading and evidence, see the works cited below, which include foundational and recent peer-reviewed sources from IEEE, Science Robotics, Nature, ACM, and more.</em>
            </div>
        </div>
        <div class="works-cited">
            <h2>Works Cited</h2>
            <ol>
                <li>Bailey, T., & Durrant-Whyte, H. (2006). Simultaneous localisation and mapping (SLAM): Part I—The essential algorithms. IEEE Robotics & Automation Magazine, 13(2), 99–110.</li>
                <li>Cadena, C., Carlone, L., Carrillo, H., Latif, Y., Scaramuzza, D., Neira, J., Reid, I., & Leonard, J. J. (2016). Past, present, and future of simultaneous localization and mapping: Toward the robust-perception age. IEEE Transactions on Robotics, 32(6), 1309–1332.</li>
                <li>Chen, J., Liu, S., & Tomlin, C. (2016). Online generation of collision-free trajectories for quadrotor flight through cluttered environments. Proceedings of ICRA.</li>
                <li>Dissanayake, M., Newman, P., Clark, S., Durrant-Whyte, H., & Csorba, M. (2001). A solution to the simultaneous localisation and map building (SLAM) problem. IEEE Transactions on Robotics and Automation, 17(3), 229–241.</li>
                <li>Gao, F., Lin, Y., Shen, S., & Liu, S. (2019). Flying on point clouds: Online trajectory generation and dynamic feasibility check. Journal of Field Robotics, 36(8), 1425–1448.</li>
                <li>Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). A formal basis for the heuristic determination of minimum cost paths. IEEE Transactions on Systems Science and Cybernetics, 4(2), 100–107.</li>
                <li>Lee, A., Chun, Y. S., Jayaraman, P. K., Sirimanna, P., Nguan, C. Y., & Hashimoto, D. A. (2024). Levels of autonomy in FDA-cleared surgical robots (2015–2023). npj Digital Medicine, 7, 113.</li>
                <li>Mohta, K., Mulgaonkar, Y., Watterson, M., Liu, S., Qu, C., Makineni, A., … Kumar, V. (2018). Fast, autonomous flight in GPS-denied and cluttered environments. Journal of Field Robotics, 35(1), 101–120.</li>
                <li>Rondoni, C., Scotto di Luzio, F., & Zollo, L. (2024). Navigation benchmarking for autonomous mobile robots in hospital environments. Scientific Reports, 14, 17943.</li>
                <li>Saeidi, H., Opfermann, J. D., Liu, Y., Orosco, R. K., Krieger, A., & Kim, P. C. W. (2022). Autonomous robotic laparoscopic surgery for intestinal anastomosis. Science Robotics, 7(62), eabj2908.</li>
                <li>Sun, V. Z., et al. (2023). Overview and results from the Mars 2020 Perseverance rover mission. Journal of Geophysical Research: Planets, 128(9), e2022JE007613.</li>
                <li>Villani, V., Pini, F., Leali, F., & Secchi, C. (2018). Survey on human–robot collaboration in industrial settings. Mechatronics, 55, 248–266.</li>
                <li>Yang, Q., Zhao, X., Hu, P., Shi, Y., & Wang, S. (2023). A review of core agricultural robot technologies for crop production. Computers and Electronics in Agriculture, 205, 107601.</li>
                <li>Zhang, L., Wang, M., Wang, C., Qiu, X., Gu, S., … Zhang, L. (2021). An autonomous excavator system for material loading tasks. Science Robotics, 6(55), eabc3164.</li>
                <li>Zhang, Y., Godin, M. A., Bellingham, J. G., & Ryan, J. P. (2012). Using an autonomous underwater vehicle to track a coastal upwelling front. IEEE Journal of Oceanic Engineering, 37(3), 338–347.</li>
                <li>Fragapane, G., de Koster, R., Sgarbossa, F., & Strandhagen, J. O. (2021). Planning and control of autonomous mobile robots for intralogistics: Literature review and research agenda. European Journal of Operational Research, 294(2), 405–426.</li>
                <li>Lackner, T., & Gronalt, M. (2024). Review of autonomous mobile robots in intralogistics. Journal of Manufacturing Systems, 73, 873–897.</li>
                <li>Bechar, A., & Vigneault, C. (2016). Agricultural robots for field operations: Concepts and components. Biosystems Engineering, 149, 94–111.</li>
                <li>Long, M., Wang, J., & Azimi, M. (2024). Equipment and operations automation in mining: A review. Machines, 12(10), 713.</li>
                <li>Nilsson, N. J. (1984). Introduction to the COMTEX microfiche edition of the SRI AI Center technical notes. AI Magazine, 5(1), 51–52.</li>
            </ol>
        </div>
    </section>
    <script src="robotics.js"></script>
</body>
</html>